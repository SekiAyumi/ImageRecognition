{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6a9f50-fdcc-4f49-9622-8385f1b8be2c",
   "metadata": {},
   "source": [
    "## simclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aedd9f7f-f08f-43bf-b406-dee5e610b4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import lightly \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from lightly import data\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc11c0b-7e9c-4921-9b07-e2d50ce285e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ac96ba-dcfd-45d8-a835-2f7114b27159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_workers = int(os.cpu_count()//2)\n",
    "seed = 1\n",
    "max_epochs = 20\n",
    "#input_size = 128\n",
    "#num_ftrs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47142a1e-77c3-4a43-870a-4f540e6510dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57f841b3-655d-4fc0-9023-2557ebb9172d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_data_train = '/home/abababam1/HandwrittenTextAlign/PRMU/simclr/data/train'\n",
    "path_to_data_test = '/home/abababam1/HandwrittenTextAlign/PRMU/simclr/data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad707e2c-781d-484f-af27-1f6b265cbc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((64, 63),antialias=True),  # 画像のサイズ変更\n",
    "    transforms.Grayscale(num_output_channels=1), #single-channel\n",
    "    transforms.RandomAffine(degrees=(-20, 20), scale=(0.8, 1.2), fill = 255),\n",
    "    transforms.ToTensor(),           # テンソルに変換\n",
    "    transforms.Normalize((0.5,), (0.5,)) #single-channel normalization\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((64, 63),antialias=True),  # 画像のサイズ変更\n",
    "    transforms.Grayscale(num_output_channels=1), #single-channel\n",
    "    transforms.ToTensor(),           # テンソルに変換\n",
    "    transforms.Normalize((0.5,), (0.5,)) #single-channel normalization\n",
    "])\n",
    "\n",
    "transform_simclr = transforms.Compose([\n",
    "    transforms.Resize((64, 63),antialias=True),  # 画像のサイズ変更\n",
    "    transforms.Grayscale(num_output_channels=1), #single-channel\n",
    "    transforms.RandomAffine(degrees=(-20, 20), scale=(0.8, 1.2), fill = 255),\n",
    "    #transforms.ToTensor(),           # テンソルに変換\n",
    "    transforms.Normalize((0.5,), (0.5,)) #single-channel normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f235a3-059f-4c09-bb2f-80c574d609d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### データローダー"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381d17b-e118-4585-b66b-aa8f5ada0358",
   "metadata": {},
   "source": [
    "・バッチサイズ（字ごとに異なる）\n",
    "・画足りない情報: ラベルに入れる\n",
    "・バッチサイズの指定を変える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a7f93bf-327b-4897-b6ab-29000eb367fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_data_dict(path_to_data):\n",
    "    d = dict() # 画像に対しラベル\n",
    "    class_indices = dict() # ラベルに対し画像が何個あるか\n",
    "    for idx, path in enumerate(glob.glob(f'{path_to_data}//*/*.png')):\n",
    "        char = path.split('/')[-2]\n",
    "        d[path] = char\n",
    "        \n",
    "        if char not in class_indices:\n",
    "            class_indices[char] = [idx]\n",
    "        else:\n",
    "            class_indices[char] += [idx]\n",
    "    return d, class_indices\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, path_to_data, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        #self.classes = classes\n",
    "        \n",
    "        data, _ = label_data_dict(path_to_data)\n",
    "        self.image_paths.extend(list(data.keys()))\n",
    "        self.labels.extend(list(data.values()))\n",
    "\n",
    "        self.classes = sorted(set(self.labels))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        label_index = self.classes.index(label)\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "\n",
    "        return image, label_index\n",
    "\n",
    "# class_indices: {'label':[data], ...}\n",
    "class ClassBatchSampler:\n",
    "    def __init__(self, class_indices):\n",
    "        self.class_indices = class_indices\n",
    "        self.classes = list(class_indices.keys())\n",
    "        #self.current_class = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 各クラスのインデックスを順に返す\n",
    "        for class_label in self.classes:\n",
    "            indices = self.class_indices[class_label]\n",
    "            #print(f\"Sampling indices for class {class_label}: {indices}\", flush=True)  # デバッグ出力\n",
    "            yield indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.classes)\n",
    "        \n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "# データセットを作成\n",
    "#dataset = CustomDataset(path_to_data, transform=transform)\n",
    "\n",
    "#_, class_indices = label_data_dict(path_to_data)\n",
    "\n",
    "# サンプラーを使ってデータローダーを作成\n",
    "#sampler = ClassBatchSampler(class_indices)\n",
    "#dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "# データローダーでクラスごとにデータを取得\n",
    "#for batch_idx, (data, labels) in enumerate(dataloader):\n",
    "#    print(f\"Batch {batch_idx}:\")\n",
    "#    print(f\"Data: {data}\")\n",
    "#    print(f\"Labels: {labels}\")\n",
    "#    print(f\"Batch size: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4bf53c0-d009-47da-b0d9-17d874145f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# データセットを作成\n",
    "dataset_train = CustomDataset(path_to_data_train, transform=transform_train)\n",
    "dataset_test = CustomDataset(path_to_data_test, transform=transform_test)\n",
    "\n",
    "_, class_indices_train = label_data_dict(path_to_data_train)\n",
    "_, class_indices_test = label_data_dict(path_to_data_test)\n",
    "\n",
    "# サンプラーを使って訓練データローダーを作成\n",
    "sampler = ClassBatchSampler(class_indices_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_sampler=sampler, num_workers=num_workers)\n",
    "\n",
    "# サンプラーを使ってテストデータローダーを作成\n",
    "sampler = ClassBatchSampler(class_indices_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccb1fc-6c0e-4198-81f8-4f00f91dc1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "    input_size=input_size,\n",
    "    vf_prob=0,\n",
    "    rr_prob=0.3,\n",
    ")\n",
    "\n",
    "dataset_train_simclr = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_data\n",
    ")\n",
    "\n",
    "dataset_test = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_data,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "dataloader_train_simclr = DataLoader(\n",
    "    dataset_train_simclr,\n",
    "    batch_size=sampler,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=sampler,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d894ae26-c343-465c-a067-1d2d5923e6ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4529c2cd-0d32-4841-88fd-2fd20035f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightly.models.modules.heads import SimCLRProjectionHead\n",
    "from lightly.loss import NTXentLoss\n",
    "\n",
    "\n",
    "class SimCLRModel(pl.LightningModule):\n",
    "    def __init__(self, batch_size=10, transform=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size \n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1, progress=True)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        # 最初の畳み込み層を1チャンネル入力に対応させる\n",
    "        self.backbone[0] = torch.nn.Conv2d(\n",
    "            in_channels=1,  # 入力チャンネル数を1に変更\n",
    "            out_channels=resnet.conv1.out_channels,\n",
    "            kernel_size=resnet.conv1.kernel_size,\n",
    "            stride=resnet.conv1.stride,\n",
    "            padding=resnet.conv1.padding,\n",
    "            bias=resnet.conv1.bias is not None\n",
    "        )\n",
    "\n",
    "        hidden_dim = resnet.fc.in_features\n",
    "        self.projection_head = SimCLRProjectionHead(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dim=2048,\n",
    "            output_dim=128,\n",
    "            num_layers=2,\n",
    "            batch_norm=True\n",
    "        )\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "        self.criterion = NTXentLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(h)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        #print(f\"Batch content: {batch}\")  # バッチの内容を出力して確認\n",
    "        (x0, x1), *_ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch  # 画像とラベルを分けて取得\n",
    "\n",
    "        # SimCLRでは、1つの画像に対して2つの異なるビューを生成\n",
    "        # データ拡張を使って2つのビューを作成\n",
    "        x0 = self.transform(images)\n",
    "        x1 = self.transform(images)\n",
    "\n",
    "        # 順伝播\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "\n",
    "        # ログに損失を記録\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):# lr=0.075*(self.batch_size)**(1/2)\n",
    "        #optim = torch.optim.SGD(\n",
    "        #    self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n",
    "        #)\n",
    "        optim = torch.optim.Adam(\n",
    "            self.parameters(), lr=1e-3, weight_decay=5e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optim, max_epochs\n",
    "        )\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af53798-54e7-441b-b15d-e8597894e051",
   "metadata": {},
   "source": [
    "#### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b602417-861a-43f5-8244-089a19a83f69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # GPUが使用可能かどうかを確認\n",
    "#print(torch.cuda.device_count())  # 使用可能なGPUの数\n",
    "#print(torch.cuda.get_device_name(0))  # GPUの名前\n",
    "accelerator='gpu' if torch.cuda.is_available() else 'cpu'\n",
    "accelerator\n",
    "devices=2 if torch.cuda.is_available() else 1\n",
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "438f28ee-9d3b-4e04-80fd-e9d3eaa5097b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabababamb1\u001b[0m (\u001b[33mabababamb1-tokyo-university-of-science\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0049e987-63be-4050-865f-7c1bd828cfbc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 3 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabababamb1\u001b[0m (\u001b[33mabababamb1-tokyo-university-of-science\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241015_195043-mzw0fb79</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/abababamb1-tokyo-university-of-science/lightning_logs/runs/mzw0fb79' target=\"_blank\">swift-disco-2</a></strong> to <a href='https://wandb.ai/abababamb1-tokyo-university-of-science/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/abababamb1-tokyo-university-of-science/lightning_logs' target=\"_blank\">https://wandb.ai/abababamb1-tokyo-university-of-science/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/abababamb1-tokyo-university-of-science/lightning_logs/runs/mzw0fb79' target=\"_blank\">https://wandb.ai/abababamb1-tokyo-university-of-science/lightning_logs/runs/mzw0fb79</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name            | Type                 | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | backbone        | Sequential           | 11.2 M | train\n",
      "1 | projection_head | SimCLRProjectionHead | 1.3 M  | train\n",
      "2 | criterion       | NTXentLoss           | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "12.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.5 M    Total params\n",
      "49.941    Total estimated model params size (MB)\n",
      "76        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 6379/6379 [05:05<00:00, 20.85it/s, v_num=fb79]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 6379/6379 [05:06<00:00, 20.81it/s, v_num=fb79]\n",
      "CPU times: user 4min 1s, sys: 1min 47s, total: 5min 49s\n",
      "Wall time: 1h 43min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#gpus = [1] if torch.cuda.is_available() else 0\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=\"all\")\n",
    "\n",
    "model = SimCLRModel(batch_size=10, transform=transform_simclr)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs, \n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=[0,1,2] if torch.cuda.is_available() else 1,  # GPUが使える場合は[2]、使えない場合は1（CPUコア数）\n",
    "    strategy=\"ddp_notebook\",  # データ並列 (DataParallel)\n",
    "    enable_progress_bar=True, # 進捗バーを有効化\n",
    "    log_every_n_steps=100,  # ログの更新間隔を設定\n",
    "    logger=wandb_logger,  # ログ機能を無効化\n",
    "    use_distributed_sampler=False  # 分散サンプラーを無効化\n",
    ")\n",
    "trainer.fit(model, dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80984ef3-7893-46ea-a3f2-35b0e06d87aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# モデルの状態を保存\n",
    "torch.save(model.state_dict(), './simclr/1015.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5341ee6f-fd52-4a10-9f83-61fb03fe3584",
   "metadata": {},
   "source": [
    "#### テストデータの埋め込み作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7008a57d-d214-4ddf-a197-cb7d0f2d33f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No embeddings generated. Please check your model and dataloader.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 26\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo embeddings generated. Please check your model and dataloader.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 26\u001b[0m embeddings, filenames \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m embeddings\n",
      "Cell \u001b[0;32mIn[40], line 21\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings, filenames\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo embeddings generated. Please check your model and dataloader.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No embeddings generated. Please check your model and dataloader."
     ]
    }
   ],
   "source": [
    "def generate_embeddings(model, dataloader):\n",
    "    \"\"\"Generates representations for all images in the dataloader with\n",
    "    the given model\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = []\n",
    "    filenames = []\n",
    "    with torch.no_grad():\n",
    "        #for img, label, fnames in dataloader:\n",
    "        for img, label in dataloader:\n",
    "            img = img.to(model.device)\n",
    "            emb = model.backbone(img).flatten(start_dim=1)\n",
    "            embeddings.append(emb)\n",
    "            #filenames.extend(fnames)\n",
    "\n",
    "    if embeddings:  # embeddingsが空でないことを確認\n",
    "        embeddings = torch.cat(embeddings, 0)\n",
    "        embeddings = normalize(embeddings)\n",
    "        return embeddings, filenames\n",
    "    else:\n",
    "        raise RuntimeError(\"No embeddings generated. Please check your model and dataloader.\")\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "embeddings, filenames = generate_embeddings(model, dataloader_test)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f87b767d-3913-4869-a0bd-1e7211587d0f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in dataloader_test:\n",
    "    print(batch)  # ここでバッチが正しく取得できているか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cbdfc-f51a-4a78-a2f3-9e79147af6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageRecognition",
   "language": "python",
   "name": "imagerecognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
